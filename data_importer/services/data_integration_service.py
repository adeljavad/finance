# data_importer/services/data_integration_service.py
import pandas as pd
import logging
from pathlib import Path
from django.db import transaction
from django.utils import timezone
from financial_system.models.document_models import DocumentHeader, DocumentItem
from financial_system.models.coding_models import ChartOfAccounts
from financial_system.services.balance_control_service import BalanceControlService
from .data_cleanup_service import DataCleanupService
from ..models import FinancialFile, ImportJob

logger = logging.getLogger(__name__)

class DataIntegrationService:
    """Ø³Ø±ÙˆÛŒØ³ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ù…Ø§Ù„ÛŒ"""
    
    def __init__(self, financial_file: FinancialFile):
        self.financial_file = financial_file
        self.company = financial_file.company
        self.period = financial_file.financial_period
        self.import_job = None
        self.balance_service = BalanceControlService()
    
    def create_import_job(self) -> ImportJob:
        """Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø§Ø± ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù†"""
        job_id = f"import_{self.company.id}_{int(timezone.now().timestamp())}"
        self.import_job = ImportJob.objects.create(
            job_id=job_id,
            financial_file=self.financial_file,
            status='PENDING'
        )
        return self.import_job
    
    def update_job_progress(self, progress: int, step: str):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ø±"""
        if self.import_job:
            self.import_job.progress = progress
            self.import_job.current_step = step
            self.import_job.save()
    
    def read_excel_data(self) -> pd.DataFrame:
        """Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„"""
        try:
            file_path = Path(self.financial_file.file_path)
            if not file_path.exists():
                raise FileNotFoundError(f"ÙØ§ÛŒÙ„ {file_path} ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„
            df = pd.read_excel(file_path)
            logger.info(f"ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§ {len(df)} Ø±Ø¯ÛŒÙ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯")
            return df
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„: {e}")
            raise
    
    def validate_data_structure(self, df: pd.DataFrame) -> dict:
        """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        results = {
            'errors': [],
            'warnings': [],
            'balance_analysis': {},
            'suggestions': []
        }
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ú¯Ø§Ø´Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø§Ø² ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„
        column_mapping = self.financial_file.columns_mapping or {}
        
        # ØªØ±Ø¬Ù…Ù‡ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ù‡ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        mapped_columns = {
            'document_number': column_mapping.get('document_number', 'Ø´Ù…Ø§Ø±Ù‡ Ø³Ù†Ø¯'),
            'document_date': column_mapping.get('document_date', 'ØªØ§Ø±ÛŒØ® Ø³Ù†Ø¯'),
            'document_description': column_mapping.get('document_description', 'Ø´Ø±Ø­ Ø³Ù†Ø¯'),
            'account_code': column_mapping.get('account_code', 'Ú©Ø¯ Ø­Ø³Ø§Ø¨'),
            'account_description': column_mapping.get('account_description', 'Ø´Ø±Ø­ Ø­Ø³Ø§Ø¨'),
            'debit': column_mapping.get('debit', 'Ø¨Ø¯Ù‡Ú©Ø§Ø±'),
            'credit': column_mapping.get('credit', 'Ø¨Ø³ØªØ§Ù†Ú©Ø§Ø±')
        }
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
        required_columns = [
            mapped_columns['document_number'],
            mapped_columns['account_code'], 
            mapped_columns['debit'],
            mapped_columns['credit']
        ]
        
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            # Ù†Ù…Ø§ÛŒØ´ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±
            persian_names = {
                'document_number': 'Ø´Ù…Ø§Ø±Ù‡ Ø³Ù†Ø¯',
                'account_code': 'Ú©Ø¯ Ø­Ø³Ø§Ø¨',
                'debit': 'Ø¨Ø¯Ù‡Ú©Ø§Ø±',
                'credit': 'Ø¨Ø³ØªØ§Ù†Ú©Ø§Ø±'
            }
            missing_standard = []
            for col in missing_columns:
                for standard_name, actual_name in mapped_columns.items():
                    if actual_name == col:
                        missing_standard.append(persian_names.get(standard_name, standard_name))
                        break
            
            results['errors'].append(f"Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯: {', '.join(missing_standard)}")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒ Ø¯Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
        for col_type, col_name in mapped_columns.items():
            if col_type in ['document_number', 'account_code', 'debit', 'credit']:
                if col_name in df.columns and df[col_name].isna().any():
                    results['warnings'].append(f"Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒ Ø¯Ø± Ø³ØªÙˆÙ† {col_name}")
        
        # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªÙˆØ§Ø²Ù†
        if mapped_columns['debit'] in df.columns and mapped_columns['credit'] in df.columns:
            balance_analysis = self._analyze_balance_advanced(df, mapped_columns)
            results['balance_analysis'] = balance_analysis
            
            if not balance_analysis['is_balanced']:
                results['warnings'].append(
                    f"Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù†: Ø¬Ù…Ø¹ Ø¨Ø¯Ù‡Ú©Ø§Ø±={balance_analysis['total_debit']}, "
                    f"Ø¬Ù…Ø¹ Ø¨Ø³ØªØ§Ù†Ú©Ø§Ø±={balance_analysis['total_credit']}, "
                    f"ØªÙØ§ÙˆØª={balance_analysis['difference']}"
                )
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø§ØµÙ„Ø§Ø­
                results['suggestions'].extend(balance_analysis['suggestions'])
        
        return results
    
    def _analyze_balance_advanced(self, df: pd.DataFrame, mapped_columns: dict) -> dict:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªÙˆØ§Ø²Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        total_debit = df[mapped_columns['debit']].sum()
        total_credit = df[mapped_columns['credit']].sum()
        difference = abs(total_debit - total_credit)
        is_balanced = difference <= 0.01
        
        # ØªØ­Ù„ÛŒÙ„ Ø§Ø³Ù†Ø§Ø¯ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù†
        unbalanced_documents = []
        suggestions = []
        
        if not is_balanced:
            # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù…Ø§Ø±Ù‡ Ø³Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
            grouped_data = df.groupby(mapped_columns['document_number'])
            
            for doc_number, group_df in grouped_data:
                doc_debit = group_df[mapped_columns['debit']].sum()
                doc_credit = group_df[mapped_columns['credit']].sum()
                doc_difference = abs(doc_debit - doc_credit)
                
                if doc_difference > 0.01:
                    unbalanced_documents.append({
                        'document_number': doc_number,
                        'debit': doc_debit,
                        'credit': doc_credit,
                        'difference': doc_difference,
                        'row_count': len(group_df)
                    })
            
            # ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
            suggestions = self._generate_balance_suggestions(df, difference, unbalanced_documents, mapped_columns)
        
        return {
            'is_balanced': is_balanced,
            'total_debit': total_debit,
            'total_credit': total_credit,
            'difference': difference,
            'unbalanced_documents': unbalanced_documents,
            'suggestions': suggestions,
            'document_count': len(df.groupby(mapped_columns['document_number'])),
            'total_rows': len(df)
        }
    
    def _generate_balance_suggestions(self, df: pd.DataFrame, difference: float, unbalanced_docs: list, mapped_columns: dict) -> list:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø§ØµÙ„Ø§Ø­ ØªÙˆØ§Ø²Ù†"""
        suggestions = []
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ 1: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±Ø¯ÛŒÙ ØªÙ†Ø¸ÛŒÙ…ÛŒ
        suggestions.append({
            'type': 'ADD_ADJUSTMENT_ROW',
            'description': f'Ø§ÙØ²ÙˆØ¯Ù† Ø±Ø¯ÛŒÙ ØªÙ†Ø¸ÛŒÙ…ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙØ§ÙˆØª {difference} Ø±ÛŒØ§Ù„',
            'implementation': 'AUTO',
            'impact': 'LOW'
        })
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ 2: Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ±
        largest_debit = df.nlargest(3, mapped_columns['debit'])[[mapped_columns['document_number'], mapped_columns['debit']]]
        largest_credit = df.nlargest(3, mapped_columns['credit'])[[mapped_columns['document_number'], mapped_columns['credit']]]
        
        suggestions.append({
            'type': 'REVIEW_LARGE_VALUES',
            'description': 'Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø¯Ù‡Ú©Ø§Ø± Ùˆ Ø¨Ø³ØªØ§Ù†Ú©Ø§Ø±',
            'implementation': 'MANUAL',
            'impact': 'MEDIUM',
            'details': {
                'largest_debit': largest_debit.to_dict('records'),
                'largest_credit': largest_credit.to_dict('records')
            }
        })
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ 3: ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø§Ø³Ù†Ø§Ø¯ Ù…Ø´Ú©Ù„â€ŒØ¯Ø§Ø±
        if unbalanced_docs:
            problematic_docs = sorted(unbalanced_docs, key=lambda x: x['difference'], reverse=True)[:3]
            suggestions.append({
                'type': 'FOCUS_PROBLEMATIC_DOCUMENTS',
                'description': 'ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ø§Ø³Ù†Ø§Ø¯ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† ØªÙØ§ÙˆØª ØªÙˆØ§Ø²Ù†',
                'implementation': 'MANUAL',
                'impact': 'HIGH',
                'details': {
                    'problematic_documents': problematic_docs
                }
            })
        
        return suggestions
    
    def create_chart_of_accounts_hierarchy(self, row: pd.Series) -> ChartOfAccounts:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ú©Ø§Ù…Ù„ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ø§Ù‡Ú©Ø§Ø±Ø§Ù†"""
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ú¯Ø§Ø´Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            column_mapping = self.financial_file.columns_mapping or {}
            mapped_columns = {
                'title1': column_mapping.get('title1', 'Title1'),
                'code1': column_mapping.get('code1', 'Code1'),
                'title2': column_mapping.get('title2', 'Title2'),
                'code2': column_mapping.get('code2', 'Code2'),
                'title3': column_mapping.get('title3', 'Title3'),
                'code3': column_mapping.get('code3', 'Code3'),
                'title4': column_mapping.get('title4', 'Title4'),
                'code4': column_mapping.get('code4', 'Code4'),
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø¯ÛŒÙ†Ú¯
            code1 = str(row[mapped_columns['code1']]) if pd.notna(row[mapped_columns['code1']]) else None
            title1 = str(row[mapped_columns['title1']]) if pd.notna(row[mapped_columns['title1']]) else None
            code2 = str(row[mapped_columns['code2']]) if pd.notna(row[mapped_columns['code2']]) else None
            title2 = str(row[mapped_columns['title2']]) if pd.notna(row[mapped_columns['title2']]) else None
            code3 = str(row[mapped_columns['code3']]) if pd.notna(row[mapped_columns['code3']]) else None
            title3 = str(row[mapped_columns['title3']]) if pd.notna(row[mapped_columns['title3']]) else None
            code4 = str(row[mapped_columns['code4']]) if pd.notna(row[mapped_columns['code4']]) else None
            title4 = str(row[mapped_columns['title4']]) if pd.notna(row[mapped_columns['title4']]) else None
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†
            parent_account = None
            
            # Ø³Ø·Ø­ 1: Ú¯Ø±ÙˆÙ‡ (CLASS)
            if code1 and title1:
                parent_account = self._get_or_create_account(
                    code=code1,
                    name=title1,
                    level='CLASS',
                    parent=None
                )
            
            # Ø³Ø·Ø­ 2: Ú©Ù„ (SUBCLASS)
            if code2 and title2 and parent_account:
                parent_account = self._get_or_create_account(
                    code=code2,
                    name=title2,
                    level='SUBCLASS',
                    parent=parent_account
                )
            
            # Ø³Ø·Ø­ 3: Ù…Ø¹ÛŒÙ† (DETAIL)
            if code3 and title3 and parent_account:
                parent_account = self._get_or_create_account(
                    code=code3,
                    name=title3,
                    level='DETAIL',
                    parent=parent_account
                )
            
            # Ø³Ø·Ø­ 4: ØªÙØµÛŒÙ„ÛŒ (DETAIL)
            if code4 and title4 and parent_account:
                final_account = self._get_or_create_account(
                    code=code4,
                    name=title4,
                    level='DETAIL',
                    parent=parent_account
                )
                return final_account
            
            # Ø§Ú¯Ø± Ø³Ø·Ø­ ØªÙØµÛŒÙ„ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø§Ø² Ø³Ø·Ø­ Ù…Ø¹ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            if parent_account:
                return parent_account
            
            # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø³Ø·Ø­ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚Øª Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†
            return self._get_or_create_account(
                code='99999',
                name='Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚Øª',
                level='DETAIL',
                parent=None
            )
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§: {e}")
            raise
    
    def _get_or_create_account(self, code: str, name: str, level: str, parent: ChartOfAccounts = None) -> ChartOfAccounts:
        """Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø­Ø³Ø§Ø¨ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù†"""
        try:
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø­Ø³Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø¯ Ùˆ Ø³Ø·Ø­
            account = ChartOfAccounts.objects.filter(
                code=code,
                level=level
            ).first()
            
            if not account:
                # Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨ Ø¬Ø¯ÛŒØ¯
                account = ChartOfAccounts.objects.create(
                    code=code,
                    name=name,
                    level=level,
                    parent=parent
                )
                logger.info(f"Ø­Ø³Ø§Ø¨ Ø¬Ø¯ÛŒØ¯ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {code} - {name} ({level})")
            else:
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø­Ø³Ø§Ø¨ Ù…ÙˆØ¬ÙˆØ¯
                if account.name != name or account.parent != parent:
                    account.name = name
                    account.parent = parent
                    account.save()
                    logger.info(f"Ø­Ø³Ø§Ø¨ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯: {code} - {name}")
            
            return account
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯/Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø­Ø³Ø§Ø¨ {code}: {e}")
            raise
    
    def map_account_code(self, account_code: str) -> ChartOfAccounts:
        """Ù…Ù¾ Ú©Ø±Ø¯Ù† Ú©Ø¯ Ø­Ø³Ø§Ø¨ Ø¨Ù‡ Ù…Ø¯Ù„ ChartOfAccounts (Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ú©Ø¯ Ù‚Ø¯ÛŒÙ…ÛŒ)"""
        try:
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø­Ø³Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø¯
            account = ChartOfAccounts.objects.filter(
                code=account_code
            ).first()
            
            if not account:
                # Ø§Ú¯Ø± Ø­Ø³Ø§Ø¨ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ ÛŒÚ© Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚Øª Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                account = ChartOfAccounts.objects.create(
                    code=account_code,
                    name=f"Ø­Ø³Ø§Ø¨ {account_code}",
                    level='DETAIL'
                )
                logger.info(f"Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚Øª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {account_code}")
            
            return account
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ù¾ Ú©Ø±Ø¯Ù† Ø­Ø³Ø§Ø¨ {account_code}: {e}")
            raise
    
    def create_documents_from_dataframe(self, df: pd.DataFrame, delete_existing_data: bool = False) -> dict:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ù…Ø§Ù„ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ DataFrame"""
        created_documents = 0
        created_items = 0
        duplicate_documents = 0
        errors = []
        
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ú¯Ø§Ø´Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            column_mapping = self.financial_file.columns_mapping or {}
            mapped_columns = {
                'document_number': column_mapping.get('document_number', 'Ø´Ù…Ø§Ø±Ù‡ Ø³Ù†Ø¯'),
                'document_date': column_mapping.get('document_date', 'ØªØ§Ø±ÛŒØ® Ø³Ù†Ø¯'),
                'document_description': column_mapping.get('document_description', 'Ø´Ø±Ø­ Ø³Ù†Ø¯'),
                'account_code': column_mapping.get('account_code', 'Ú©Ø¯ Ø­Ø³Ø§Ø¨'),
                'debit': column_mapping.get('debit', 'Ø¨Ø¯Ù‡Ú©Ø§Ø±'),
                'credit': column_mapping.get('credit', 'Ø¨Ø³ØªØ§Ù†Ú©Ø§Ø±')
            }
            
            # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù…Ø§Ø±Ù‡ Ø³Ù†Ø¯
            grouped_data = df.groupby(mapped_columns['document_number'])
            
            for document_number, group_df in grouped_data:
                try:
                    # Ù„Ø§Ú¯ ÙˆØ¶Ø¹ÛŒØª Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ - Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±
                    logger.info(f"ğŸ” Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ù†Ø¯ {document_number}")
                    logger.info(f"ğŸ” delete_existing_data Ø¯Ø± create_documents_from_dataframe: {delete_existing_data}")
                    logger.info(f"ğŸ” Ù†ÙˆØ¹ delete_existing_data: {type(delete_existing_data)}")
                    
                    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø³Ù†Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ
                    existing_document = DocumentHeader.objects.filter(
                        company=self.company,
                        period=self.period,
                        document_number=document_number
                    ).first()
                    
                    logger.info(f"ğŸ” Ø³Ù†Ø¯ {document_number} Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯: {existing_document is not None}")
                    
                    if existing_document:
                        if delete_existing_data:
                            # Ø§Ú¯Ø± delete_existing_data=True Ø¨Ø§Ø´Ø¯ØŒ Ø³Ù†Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯
                            logger.info(f"ğŸ—‘ï¸ Ø­Ø°Ù Ø³Ù†Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ: {document_number}")
                            existing_document.delete()
                            logger.info(f"âœ… Ø³Ù†Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ø´Ø¯: {document_number}")
                            
                            # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø±Ø¨Ø±Ú¯ Ø³Ù†Ø¯ Ø¬Ø¯ÛŒØ¯
                            document_header = self._create_document_header(document_number, group_df, mapped_columns)
                            created_documents += 1
                            
                            # Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ø±ØªÛŒÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ø¯
                            for index, row in group_df.iterrows():
                                self._create_document_item(document_header, row, index + 1, mapped_columns)
                                created_items += 1
                            
                        else:
                            # Ø§Ú¯Ø± delete_existing_data=False Ø¨Ø§Ø´Ø¯ØŒ Ø³Ù†Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                            duplicate_documents += 1
                            logger.warning(f"âŒ Ø³Ù†Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯: {document_number}")
                            continue
                    else:
                        logger.info(f"âœ… Ø³Ù†Ø¯ Ø¬Ø¯ÛŒØ¯: {document_number} (Ø³Ù†Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)")
                        
                        # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø±Ø¨Ø±Ú¯ Ø³Ù†Ø¯ Ø¬Ø¯ÛŒØ¯
                        document_header = self._create_document_header(document_number, group_df, mapped_columns)
                        created_documents += 1
                        
                        # Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ø±ØªÛŒÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ø¯
                        for index, row in group_df.iterrows():
                            self._create_document_item(document_header, row, index + 1, mapped_columns)
                            created_items += 1
                    
                    # Ø§Ú¯Ø± delete_existing_data=True Ø¨Ø§Ø´Ø¯ØŒ Ù„Ø§Ú¯ Ø¨Ø²Ù† Ú©Ù‡ Ø³Ù†Ø¯ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                    if delete_existing_data:
                        logger.info(f"âœ… Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ Ø¬Ø¯ÛŒØ¯: {document_number} (Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯)")
                        
                except Exception as e:
                    errors.append(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ {document_number}: {str(e)}")
                    logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ {document_number}: {e}")
                    continue
            
            result = {
                'document_count': created_documents,
                'item_count': created_items,
                'duplicate_documents': duplicate_documents,
                'status': 'success'
            }
            
            if errors:
                result['warnings'] = errors
                result['status'] = 'partial_success'
            
            return result
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯: {e}")
            raise
    
    def _create_document_header(self, document_number: str, group_df: pd.DataFrame, mapped_columns: dict) -> DocumentHeader:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø±Ø¨Ø±Ú¯ Ø³Ù†Ø¯"""
        try:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¬Ù…Ø¹ Ø¨Ø¯Ù‡Ú©Ø§Ø± Ùˆ Ø¨Ø³ØªØ§Ù†Ú©Ø§Ø±
            total_debit = float(group_df[mapped_columns['debit']].sum())
            total_credit = float(group_df[mapped_columns['credit']].sum())
            
            # Ø¨Ø±Ø±Ø³ÛŒ ØªÙˆØ§Ø²Ù†
            is_balanced = abs(total_debit - total_credit) <= 0.01
            
            # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ® ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ‚ÛŒÙ… (Ø¨Ø¯ÙˆÙ† ØªØ¨Ø¯ÛŒÙ„)
            document_date = None
            if mapped_columns['document_date'] in group_df.columns:
                persian_date = group_df[mapped_columns['document_date']].iloc[0]
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ùˆ Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
                if pd.notna(persian_date):
                    document_date = str(persian_date).strip()
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø®Ø§Ù„ÛŒ (ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨Ù‡ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
            document_header = DocumentHeader.objects.create(
                document_number=document_number,
                document_type='SANAD',
                document_date=document_date,
                description='',  # ØªÙˆØ¶ÛŒØ­Ø§Øª Ø®Ø§Ù„ÛŒ - Ø¨Ù‡ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                company=self.company,
                period=self.period,
                total_debit=total_debit,
                total_credit=total_credit,
                is_balanced=is_balanced
            )
            
            return document_header
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø±Ø¨Ø±Ú¯ Ø³Ù†Ø¯ {document_number}: {e}")
            raise
    
    def _create_document_item(self, document_header: DocumentHeader, row: pd.Series, row_number: int, mapped_columns: dict):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ø±ØªÛŒÚ©Ù„ Ø³Ù†Ø¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ùˆ Ø§Ù†ØªÙ‚Ø§Ù„ ØªÙˆØ¶ÛŒØ­Ø§Øª"""
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ù¾ Ú©Ø±Ø¯Ù† Ø­Ø³Ø§Ø¨
            # Ø§Ú¯Ø± Ø³Ø·ÙˆØ­ Ú©Ø¯ÛŒÙ†Ú¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø§Ø² Ù…ØªØ¯ Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            try:
                account = self.create_chart_of_accounts_hierarchy(row)
            except Exception as hierarchy_error:
                logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ Ù‚Ø¯ÛŒÙ…ÛŒ: {hierarchy_error}")
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† fallback
                if mapped_columns['account_code'] in row and pd.notna(row[mapped_columns['account_code']]):
                    account_code = str(row[mapped_columns['account_code']])
                    account = self.map_account_code(account_code)
                else:
                    # Ø§Ú¯Ø± Ú©Ø¯ Ø­Ø³Ø§Ø¨ Ù‡Ù… ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚Øª Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†
                    account = self.map_account_code('99999')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø² Ø³ØªÙˆÙ† Ø´Ø±Ø­ Ø³Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø¢ÛŒØªÙ…
            item_description = ''
            if mapped_columns['document_description'] in row and pd.notna(row[mapped_columns['document_description']]):
                item_description = str(row[mapped_columns['document_description']]).strip()
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ø±ØªÛŒÚ©Ù„ Ø¨Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ù…Ù†ØªÙ‚Ù„ Ø´Ø¯Ù‡
            DocumentItem.objects.create(
                document=document_header,
                row_number=row_number,
                account=account,
                debit=row[mapped_columns['debit']] if pd.notna(row[mapped_columns['debit']]) else 0,
                credit=row[mapped_columns['credit']] if pd.notna(row[mapped_columns['credit']]) else 0,
                description=item_description,
                cost_center=row.get('Ù…Ø±Ú©Ø² Ù‡Ø²ÛŒÙ†Ù‡', '') if pd.notna(row.get('Ù…Ø±Ú©Ø² Ù‡Ø²ÛŒÙ†Ù‡')) else '',
                project_code=row.get('Ú©Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡', '') if pd.notna(row.get('Ú©Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡')) else ''
            )
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ø±ØªÛŒÚ©Ù„ Ø³Ù†Ø¯ {document_header.document_number} Ø±Ø¯ÛŒÙ {row_number}: {e}")
            raise
    
    def process_import(self, delete_existing_data: bool = False) -> dict:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù…Ú©Ø§Ù† Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ"""
        try:
            # Ù„Ø§Ú¯ ÙˆØ¶Ø¹ÛŒØª delete_existing_data
            logger.info(f"ğŸ” DataIntegrationService.process_import - delete_existing_data: {delete_existing_data}")
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø§Ø± ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù†
            self.create_import_job()
            self.import_job.start_processing()
            
            # Ù…Ø±Ø­Ù„Ù‡ 0: Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ (Ø¯Ø± ØµÙˆØ±Øª Ø¯Ø±Ø®ÙˆØ§Ø³Øª)
            if delete_existing_data:
                logger.info("ğŸ” Ø´Ø±ÙˆØ¹ Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ")
                self.update_job_progress(10, 'Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ')
                cleanup_result = self._delete_existing_data()
                
                if cleanup_result['status'] == 'failed':
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ: {cleanup_result['message']}")
                    self.import_job.fail(f"Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ: {cleanup_result['message']}")
                    return {
                        'status': 'failed',
                        'errors': [f"Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ: {cleanup_result['message']}"],
                        'document_count': 0,
                        'item_count': 0
                    }
                
                logger.info(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯: {cleanup_result['deleted_documents']} Ø³Ù†Ø¯ØŒ {cleanup_result['deleted_items']} Ø¢Ø±ØªÛŒÚ©Ù„")
            else:
                logger.info("ğŸ” Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            
            # Ù…Ø±Ø­Ù„Ù‡ 1: Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            self.update_job_progress(25, 'Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„')
            df = self.read_excel_data()
            
            # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
            self.update_job_progress(50, 'Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§')
            validation_results = self.validate_data_structure(df)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ
            if validation_results['errors']:
                self.import_job.fail(f"Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {', '.join(validation_results['errors'])}")
                return {
                    'status': 'failed',
                    'errors': validation_results['errors'],
                    'warnings': validation_results['warnings'],
                    'balance_analysis': validation_results['balance_analysis'],
                    'suggestions': validation_results['suggestions'],
                    'document_count': 0,
                    'item_count': 0
                }
            
            # Ù…Ø±Ø­Ù„Ù‡ 3: Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ú©Ø§Ù…Ù„ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§
            self.update_job_progress(60, 'Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§')
            
            # Ù„Ø§Ú¯ Ø¯ÛŒØ¨Ø§Ú¯: Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± DataFrame
            logger.info(f"ğŸ” Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± DataFrame: {list(df.columns)}")
            
            # Ù„Ø§Ú¯ Ø¯ÛŒØ¨Ø§Ú¯: Ø¨Ø±Ø±Ø³ÛŒ Ù†Ú¯Ø§Ø´Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            column_mapping = self.financial_file.columns_mapping or {}
            logger.info(f"ğŸ” Ù†Ú¯Ø§Ø´Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {column_mapping}")
            
            # Ù„Ø§Ú¯ Ø¯ÛŒØ¨Ø§Ú¯: Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ø¯ÛŒÙ†Ú¯
            coding_columns = ['Title1', 'Code1', 'Title2', 'Code2', 'Title3', 'Code3', 'Title4', 'Code4']
            for col in coding_columns:
                exists = col in df.columns
                logger.info(f"ğŸ” Ø³ØªÙˆÙ† {col}: {'âœ… Ù…ÙˆØ¬ÙˆØ¯' if exists else 'âŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª'}")
            
            hierarchy_results = self.create_complete_chart_of_accounts_hierarchy(df)
            
            if hierarchy_results['errors']:
                logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§: {', '.join(hierarchy_results['errors'])}")
            else:
                logger.info(f"âœ… Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {hierarchy_results['created_levels']}")
            
            # Ù…Ø±Ø­Ù„Ù‡ 4: Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯
            self.update_job_progress(75, 'Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ù…Ø§Ù„ÛŒ')
            result = self.create_documents_from_dataframe(df, delete_existing_data=delete_existing_data)
            
            # Ù…Ø±Ø­Ù„Ù‡ 4: ØªÚ©Ù…ÛŒÙ„
            self.update_job_progress(100, 'ØªÚ©Ù…ÛŒÙ„ Ø¹Ù…Ù„ÛŒØ§Øª')
            self.import_job.complete(result)
            
            # Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡
            self.financial_file.mark_as_imported({
                'document_count': result['document_count'],
                'item_count': result['item_count'],
                'validation_results': validation_results,
                'delete_existing_data': delete_existing_data
            })
            
            logger.info(f"Ø¹Ù…Ù„ÛŒØ§Øª ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯: {result['document_count']} Ø³Ù†Ø¯ØŒ {result['item_count']} Ø¢Ø±ØªÛŒÚ©Ù„")
            
            return {
                'status': 'success',
                'document_count': result['document_count'],
                'item_count': result['item_count'],
                'warnings': validation_results['warnings'],
                'balance_analysis': validation_results['balance_analysis'],
                'suggestions': validation_results['suggestions'],
                'delete_existing_data': delete_existing_data
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù†: {e}")
            if self.import_job:
                self.import_job.fail(str(e))
            raise
    
    def create_complete_chart_of_accounts_hierarchy(self, df: pd.DataFrame) -> dict:
        """Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ú©Ø§Ù…Ù„ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ø§Ø² ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„"""
        results = {
            'created_levels': {
                'CLASS': 0,
                'SUBCLASS': 0, 
                'DETAIL': 0
            },
            'total_rows_processed': 0,
            'errors': []
        }
        
        try:
            logger.info("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§")
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ú¯Ø§Ø´Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            column_mapping = self.financial_file.columns_mapping or {}
            logger.info(f"ğŸ” Ù†Ú¯Ø§Ø´Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ø¯ÛŒÙ†Ú¯: {column_mapping}")
            
            mapped_columns = {
                'title1': column_mapping.get('title1', 'Title1'),
                'code1': column_mapping.get('code1', 'Code1'),
                'title2': column_mapping.get('title2', 'Title2'),
                'code2': column_mapping.get('code2', 'Code2'),
                'title3': column_mapping.get('title3', 'Title3'),
                'code3': column_mapping.get('code3', 'Code3'),
                'title4': column_mapping.get('title4', 'Title4'),
                'code4': column_mapping.get('code4', 'Code4'),
            }
            
            logger.info(f"ğŸ” Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù†Ú¯Ø§Ø´Øª Ø´Ø¯Ù‡: {mapped_columns}")
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ø¯ÛŒÙ†Ú¯ Ø¯Ø± DataFrame
            for col_name, col_value in mapped_columns.items():
                exists = col_value in df.columns
                logger.info(f"ğŸ” Ø³ØªÙˆÙ† {col_name} ({col_value}): {'âœ… Ù…ÙˆØ¬ÙˆØ¯' if exists else 'âŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª'}")
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„
            logger.info(f"ğŸ“Š Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… {len(df)} Ø±Ú©ÙˆØ±Ø¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„")
            
            # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡
            level1_accounts = {}
            level2_accounts = {}
            level3_accounts = {}
            level4_accounts = {}
            
            for index, row in df.iterrows():
                try:
                    results['total_rows_processed'] += 1
                    
                    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø·ÙˆØ­ Ú©Ø¯ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø±Ú©ÙˆØ±Ø¯
                    self._process_account_hierarchy_for_row(row, mapped_columns, level1_accounts, level2_accounts, level3_accounts, level4_accounts)
                    
                    # Ù„Ø§Ú¯ Ù¾ÛŒØ´Ø±ÙØª Ù‡Ø± 100 Ø±Ú©ÙˆØ±Ø¯
                    if (index + 1) % 100 == 0:
                        logger.info(f"ğŸ“Š Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ú©ÙˆØ±Ø¯ {index + 1} Ø§Ø² {len(df)}")
                        
                except Exception as e:
                    error_msg = f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ú©ÙˆØ±Ø¯ {index + 1}: {e}"
                    logger.error(error_msg)
                    results['errors'].append(error_msg)
                    continue
            
            # Ø´Ù…Ø§Ø±Ø´ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡
            results['created_levels']['CLASS'] = len(level1_accounts)
            results['created_levels']['SUBCLASS'] = len(level2_accounts)
            results['created_levels']['DETAIL'] = len(level3_accounts) + len(level4_accounts)
            
            total_accounts = len(level1_accounts) + len(level2_accounts) + len(level3_accounts) + len(level4_accounts)
            logger.info(f"ğŸ‰ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: CLASS={len(level1_accounts)}, SUBCLASS={len(level2_accounts)}, DETAIL={len(level3_accounts) + len(level4_accounts)} (Ù…Ø¬Ù…ÙˆØ¹: {total_accounts} Ø­Ø³Ø§Ø¨)")
            logger.info(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {results['total_rows_processed']} Ø§Ø² {len(df)}")
            
            return results
            
        except Exception as e:
            error_msg = f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§: {e}"
            logger.error(error_msg)
            import traceback
            logger.error(f"ğŸ” Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§: {traceback.format_exc()}")
            results['errors'].append(error_msg)
            return results
    
    def _process_account_hierarchy_for_row(self, row: pd.Series, mapped_columns: dict, 
                                         level1_accounts: dict, level2_accounts: dict, 
                                         level3_accounts: dict, level4_accounts: dict):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø±Ú©ÙˆØ±Ø¯ Ø®Ø§Øµ"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø¯ÛŒÙ†Ú¯ Ø§Ø² Ø±Ú©ÙˆØ±Ø¯
            code1 = str(row[mapped_columns['code1']]) if pd.notna(row[mapped_columns['code1']]) and str(row[mapped_columns['code1']]).strip() != '' else None
            title1 = str(row[mapped_columns['title1']]) if pd.notna(row[mapped_columns['title1']]) and str(row[mapped_columns['title1']]).strip() != '' else None
            code2 = str(row[mapped_columns['code2']]) if pd.notna(row[mapped_columns['code2']]) and str(row[mapped_columns['code2']]).strip() != '' else None
            title2 = str(row[mapped_columns['title2']]) if pd.notna(row[mapped_columns['title2']]) and str(row[mapped_columns['title2']]).strip() != '' else None
            code3 = str(row[mapped_columns['code3']]) if pd.notna(row[mapped_columns['code3']]) and str(row[mapped_columns['code3']]).strip() != '' else None
            title3 = str(row[mapped_columns['title3']]) if pd.notna(row[mapped_columns['title3']]) and str(row[mapped_columns['title3']]).strip() != '' else None
            code4 = str(row[mapped_columns['code4']]) if pd.notna(row[mapped_columns['code4']]) and str(row[mapped_columns['code4']]).strip() != '' else None
            title4 = str(row[mapped_columns['title4']]) if pd.notna(row[mapped_columns['title4']]) and str(row[mapped_columns['title4']]).strip() != '' else None
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†
            parent_account = None
            
            # Ø³Ø·Ø­ 1: Ú¯Ø±ÙˆÙ‡ (CLASS)
            if code1 and title1:
                if code1 not in level1_accounts:
                    account = self._get_or_create_account(
                        code=code1,
                        name=title1,
                        level='CLASS',
                        parent=None
                    )
                    level1_accounts[code1] = account
                parent_account = level1_accounts[code1]
            
            # Ø³Ø·Ø­ 2: Ú©Ù„ (SUBCLASS)
            if code2 and title2 and parent_account:
                if code2 not in level2_accounts:
                    account = self._get_or_create_account(
                        code=code2,
                        name=title2,
                        level='SUBCLASS',
                        parent=parent_account
                    )
                    level2_accounts[code2] = account
                parent_account = level2_accounts[code2]
            
            # Ø³Ø·Ø­ 3: Ù…Ø¹ÛŒÙ† (DETAIL)
            if code3 and title3 and parent_account:
                if code3 not in level3_accounts:
                    account = self._get_or_create_account(
                        code=code3,
                        name=title3,
                        level='DETAIL',
                        parent=parent_account
                    )
                    level3_accounts[code3] = account
                parent_account = level3_accounts[code3]
            
            # Ø³Ø·Ø­ 4: ØªÙØµÛŒÙ„ÛŒ (DETAIL)
            if code4 and title4 and parent_account:
                if code4 not in level4_accounts:
                    account = self._get_or_create_account(
                        code=code4,
                        name=title4,
                        level='DETAIL',
                        parent=parent_account
                    )
                    level4_accounts[code4] = account
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ù„Ø³Ù„Ù‡ Ù…Ø±Ø§ØªØ¨ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø±Ú©ÙˆØ±Ø¯: {e}")
            raise
    
    def _extract_level1_accounts(self, df: pd.DataFrame, mapped_columns: dict) -> dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ CLASS (Code1, Title1)"""
        level1_accounts = {}
        
        try:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Code1, Title1 Ù…ØªÙ…Ø§ÛŒØ²
            if mapped_columns['code1'] in df.columns and mapped_columns['title1'] in df.columns:
                level1_data = df[[mapped_columns['code1'], mapped_columns['title1']]].dropna().drop_duplicates()
                
                for _, row in level1_data.iterrows():
                    code1 = str(row[mapped_columns['code1']])
                    title1 = str(row[mapped_columns['title1']])
                    
                    # Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨ Ø³Ø·Ø­ CLASS
                    account = self._get_or_create_account(
                        code=code1,
                        name=title1,
                        level='CLASS',
                        parent=None
                    )
                    
                    level1_accounts[code1] = account
                    logger.debug(f"Ø­Ø³Ø§Ø¨ CLASS Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {code1} - {title1}")
            
            return level1_accounts
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ CLASS: {e}")
            return level1_accounts
    
    def _extract_level2_accounts(self, df: pd.DataFrame, mapped_columns: dict, level1_accounts: dict) -> dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ SUBCLASS (Code2, Title2) Ø¨Ø§ ÙˆØ§Ù„Ø¯ Ù…Ù†Ø§Ø³Ø¨"""
        level2_accounts = {}
        
        try:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Code2, Title2 Ù…ØªÙ…Ø§ÛŒØ²
            if mapped_columns['code2'] in df.columns and mapped_columns['title2'] in df.columns:
                level2_data = df[[mapped_columns['code1'], mapped_columns['code2'], mapped_columns['title2']]].dropna().drop_duplicates()
                
                for _, row in level2_data.iterrows():
                    code1 = str(row[mapped_columns['code1']]) if pd.notna(row[mapped_columns['code1']]) else None
                    code2 = str(row[mapped_columns['code2']])
                    title2 = str(row[mapped_columns['title2']])
                    
                    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙˆØ§Ù„Ø¯ Ù…Ù†Ø§Ø³Ø¨ (Ø³Ø·Ø­ CLASS)
                    parent_account = level1_accounts.get(code1) if code1 else None
                    
                    if parent_account:
                        # Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨ Ø³Ø·Ø­ SUBCLASS
                        account = self._get_or_create_account(
                            code=code2,
                            name=title2,
                            level='SUBCLASS',
                            parent=parent_account
                        )
                        
                        level2_accounts[code2] = account
                        logger.debug(f"Ø­Ø³Ø§Ø¨ SUBCLASS Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {code2} - {title2} (ÙˆØ§Ù„Ø¯: {code1})")
                    else:
                        logger.warning(f"ÙˆØ§Ù„Ø¯ ÛŒØ§ÙØª Ù†Ø´Ø¯ Ø¨Ø±Ø§ÛŒ Ø­Ø³Ø§Ø¨ SUBCLASS: {code2} - {title2}")
            
            return level2_accounts
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ SUBCLASS: {e}")
            return level2_accounts
    
    def _extract_level3_accounts(self, df: pd.DataFrame, mapped_columns: dict, level2_accounts: dict) -> dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ DETAIL (Code3, Title3) Ø¨Ø§ ÙˆØ§Ù„Ø¯ Ù…Ù†Ø§Ø³Ø¨"""
        level3_accounts = {}
        
        try:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Code3, Title3 Ù…ØªÙ…Ø§ÛŒØ²
            if mapped_columns['code3'] in df.columns and mapped_columns['title3'] in df.columns:
                level3_data = df[[mapped_columns['code2'], mapped_columns['code3'], mapped_columns['title3']]].dropna().drop_duplicates()
                
                for _, row in level3_data.iterrows():
                    code2 = str(row[mapped_columns['code2']]) if pd.notna(row[mapped_columns['code2']]) else None
                    code3 = str(row[mapped_columns['code3']])
                    title3 = str(row[mapped_columns['title3']])
                    
                    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙˆØ§Ù„Ø¯ Ù…Ù†Ø§Ø³Ø¨ (Ø³Ø·Ø­ SUBCLASS)
                    parent_account = level2_accounts.get(code2) if code2 else None
                    
                    if parent_account:
                        # Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨ Ø³Ø·Ø­ DETAIL
                        account = self._get_or_create_account(
                            code=code3,
                            name=title3,
                            level='DETAIL',
                            parent=parent_account
                        )
                        
                        level3_accounts[code3] = account
                        logger.debug(f"Ø­Ø³Ø§Ø¨ DETAIL Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {code3} - {title3} (ÙˆØ§Ù„Ø¯: {code2})")
                    else:
                        logger.warning(f"ÙˆØ§Ù„Ø¯ ÛŒØ§ÙØª Ù†Ø´Ø¯ Ø¨Ø±Ø§ÛŒ Ø­Ø³Ø§Ø¨ DETAIL: {code3} - {title3}")
            
            return level3_accounts
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ DETAIL: {e}")
            return level3_accounts
    
    def _extract_level4_accounts(self, df: pd.DataFrame, mapped_columns: dict, level3_accounts: dict) -> dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ DETAIL (Code4, Title4) Ø¨Ø§ ÙˆØ§Ù„Ø¯ Ù…Ù†Ø§Ø³Ø¨"""
        level4_accounts = {}
        
        try:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Code4, Title4 Ù…ØªÙ…Ø§ÛŒØ²
            if mapped_columns['code4'] in df.columns and mapped_columns['title4'] in df.columns:
                level4_data = df[[mapped_columns['code3'], mapped_columns['code4'], mapped_columns['title4']]].dropna().drop_duplicates()
                
                for _, row in level4_data.iterrows():
                    code3 = str(row[mapped_columns['code3']]) if pd.notna(row[mapped_columns['code3']]) else None
                    code4 = str(row[mapped_columns['code4']])
                    title4 = str(row[mapped_columns['title4']])
                    
                    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙˆØ§Ù„Ø¯ Ù…Ù†Ø§Ø³Ø¨ (Ø³Ø·Ø­ DETAIL)
                    parent_account = level3_accounts.get(code3) if code3 else None
                    
                    if parent_account:
                        # Ø§ÛŒØ¬Ø§Ø¯ Ø­Ø³Ø§Ø¨ Ø³Ø·Ø­ DETAIL
                        account = self._get_or_create_account(
                            code=code4,
                            name=title4,
                            level='DETAIL',
                            parent=parent_account
                        )
                        
                        level4_accounts[code4] = account
                        logger.debug(f"Ø­Ø³Ø§Ø¨ DETAIL Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {code4} - {title4} (ÙˆØ§Ù„Ø¯: {code3})")
                    else:
                        logger.warning(f"ÙˆØ§Ù„Ø¯ ÛŒØ§ÙØª Ù†Ø´Ø¯ Ø¨Ø±Ø§ÛŒ Ø­Ø³Ø§Ø¨ DETAIL: {code4} - {title4}")
            
            return level4_accounts
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø³Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø·Ø­ DETAIL: {e}")
            return level4_accounts

    def _delete_existing_data(self) -> dict:
        """Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ"""
        try:
            cleanup_service = DataCleanupService(self.company, self.period)
            return cleanup_service.delete_imported_data()
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ: {e}")
            return {
                'deleted_documents': 0,
                'deleted_items': 0,
                'status': 'failed',
                'message': str(e)
            }


def import_financial_data(financial_file_id: int, delete_existing_data: bool = False) -> dict:
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ø§ Ø§Ù…Ú©Ø§Ù† Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ"""
    try:
        financial_file = FinancialFile.objects.get(id=financial_file_id)
        service = DataIntegrationService(financial_file)
        return service.process_import(delete_existing_data=delete_existing_data)
        
    except FinancialFile.DoesNotExist:
        logger.error(f"ÙØ§ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù‡ {financial_file_id} ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return {
            'status': 'failed',
            'errors': ['ÙØ§ÛŒÙ„ Ù…Ø§Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯'],
            'document_count': 0,
            'item_count': 0
        }
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
        return {
            'status': 'failed',
            'errors': [str(e)],
            'document_count': 0,
            'item_count': 0
        }
